{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Overlapping Width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the experiment __exp-SphericalAlignment__, which is to test the correctness of camera metrics, we felt strong scepticism on the camera sensor size and focal length values that we get from the JSON file.\n",
    "\n",
    "This experiment is for measuring AOV(angle of view) and PPD(pixels per degree) by manually estimate overlapping width and height of image frames, thus to ensure the correctness of JSON contents.\n",
    "\n",
    "Overlapping areas are calculated from matching feature points of adjacent images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from libpano import MetaData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final test data is used for this experiment. We load the JSON file and analysed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = 'recent-04'\n",
    "folder = '../images/' + image_id\n",
    "meta = MetaData.MetaData(folder)\n",
    "df = meta.grid_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Panorama metrics calculated from the JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera Metrics:\n",
      "\tFocal Length: 4.4589 mm\n",
      "\tFocal Length: 1588.26 px\n",
      "\tSensor Size: 4.2447996 x 5.6447997 mm\n",
      "\tPixels per mm: 356.20 x 357.14 px\n",
      "PanoramaMetrics:\n",
      "\tFrame Count: 15 x 5\n",
      "\tFrame Size: 1512px x 2016px\n",
      "\tInterval Angle: 24.0︒ x 36.0︒\n",
      "\tAoV: 50.9081︒ x 64.6661︒\n",
      "\tAoV: 0.8885 x 1.1286\n",
      "\tPPR: 1701.7168px x 1786.2268px\n",
      "\tPanorama Size: 10692.2019px x 5611.5971px\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(meta.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overlapping width should be calculated on the middle row of the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row</th>\n",
       "      <th>col</th>\n",
       "      <th>uri</th>\n",
       "      <th>pitch</th>\n",
       "      <th>roll</th>\n",
       "      <th>yaw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>img-r1-167.jpg</td>\n",
       "      <td>1.618314</td>\n",
       "      <td>0.672979</td>\n",
       "      <td>17.196747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>img-r1-192.jpg</td>\n",
       "      <td>1.405421</td>\n",
       "      <td>-0.227626</td>\n",
       "      <td>41.420685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>img-r1-217.jpg</td>\n",
       "      <td>1.407111</td>\n",
       "      <td>1.317603</td>\n",
       "      <td>66.893280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>img-r1-240.jpg</td>\n",
       "      <td>1.669483</td>\n",
       "      <td>1.424618</td>\n",
       "      <td>89.764771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>img-r1-264.jpg</td>\n",
       "      <td>1.795640</td>\n",
       "      <td>0.912027</td>\n",
       "      <td>113.928802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>img-r1-286.jpg</td>\n",
       "      <td>0.791613</td>\n",
       "      <td>0.535418</td>\n",
       "      <td>136.117828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>img-r1-310.jpg</td>\n",
       "      <td>1.689086</td>\n",
       "      <td>1.997290</td>\n",
       "      <td>160.312744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>img-r1-335.jpg</td>\n",
       "      <td>1.852506</td>\n",
       "      <td>3.240176</td>\n",
       "      <td>185.285416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>img-r1-000.jpg</td>\n",
       "      <td>1.814764</td>\n",
       "      <td>1.945364</td>\n",
       "      <td>209.926773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>img-r1-022.jpg</td>\n",
       "      <td>1.616959</td>\n",
       "      <td>2.058648</td>\n",
       "      <td>232.099152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>img-r1-048.jpg</td>\n",
       "      <td>1.781996</td>\n",
       "      <td>2.166965</td>\n",
       "      <td>257.511200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>img-r1-070.jpg</td>\n",
       "      <td>1.651889</td>\n",
       "      <td>1.609781</td>\n",
       "      <td>280.285095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>img-r1-095.jpg</td>\n",
       "      <td>1.863805</td>\n",
       "      <td>1.228925</td>\n",
       "      <td>304.976898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>img-r1-118.jpg</td>\n",
       "      <td>1.534545</td>\n",
       "      <td>1.944360</td>\n",
       "      <td>328.037811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>img-r1-143.jpg</td>\n",
       "      <td>1.842209</td>\n",
       "      <td>1.463921</td>\n",
       "      <td>353.075012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    row  col             uri     pitch      roll         yaw\n",
       "30    2    0  img-r1-167.jpg  1.618314  0.672979   17.196747\n",
       "31    2    1  img-r1-192.jpg  1.405421 -0.227626   41.420685\n",
       "32    2    2  img-r1-217.jpg  1.407111  1.317603   66.893280\n",
       "33    2    3  img-r1-240.jpg  1.669483  1.424618   89.764771\n",
       "34    2    4  img-r1-264.jpg  1.795640  0.912027  113.928802\n",
       "35    2    5  img-r1-286.jpg  0.791613  0.535418  136.117828\n",
       "36    2    6  img-r1-310.jpg  1.689086  1.997290  160.312744\n",
       "37    2    7  img-r1-335.jpg  1.852506  3.240176  185.285416\n",
       "38    2    8  img-r1-000.jpg  1.814764  1.945364  209.926773\n",
       "39    2    9  img-r1-022.jpg  1.616959  2.058648  232.099152\n",
       "40    2   10  img-r1-048.jpg  1.781996  2.166965  257.511200\n",
       "41    2   11  img-r1-070.jpg  1.651889  1.609781  280.285095\n",
       "42    2   12  img-r1-095.jpg  1.863805  1.228925  304.976898\n",
       "43    2   13  img-r1-118.jpg  1.534545  1.944360  328.037811\n",
       "44    2   14  img-r1-143.jpg  1.842209  1.463921  353.075012"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "center_row = df.row.nunique() // 2\n",
    "df[df.row == center_row]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The roll differences between adjacent images are 1.5 degree at most and we think this can be ignored.\n",
    "\n",
    "Image frames' yaw interval is 24 degree but there are some variations and they should be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "uris = df[df.row == center_row].uri.values.tolist()\n",
    "yaws = df[df.row == center_row].yaw.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function that gets non-overlapping width of two adjacent images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_overlapping_width(img_name1, img_name2, max_overlap_ratio=0.7):\n",
    "    # load images\n",
    "    img1 = cv.imread(img_name1)\n",
    "    img2 = cv.imread(img_name2)\n",
    "\n",
    "    # conver into gray scale\n",
    "    gray1 = cv.cvtColor(img1, cv.COLOR_BGR2GRAY)\n",
    "    gray2 = cv.cvtColor(img2, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # find feature points from the gray-scale images\n",
    "    finder = cv.ORB_create()\n",
    "    feature1 = cv.detail.computeImageFeatures2(finder, gray1)\n",
    "    feature2 = cv.detail.computeImageFeatures2(finder, gray2)\n",
    "\n",
    "    # match key points\n",
    "    matcher = cv.detail.BestOf2NearestMatcher_create(False, 0.3)\n",
    "    matches = matcher.apply2([feature1, feature2])\n",
    "    \n",
    "    # as the function above returns 4 DMatch objects - 0:0, 0:1, 1:0, 1:1, we should choose correct one 0:1\n",
    "    real_match = None\n",
    "    for match in matches:\n",
    "        if match.src_img_idx == 0 and match.dst_img_idx == 1:\n",
    "            real_match = match\n",
    "            break\n",
    "\n",
    "    # get masked match info\n",
    "    matches_list = real_match.getMatches()\n",
    "    matches_mask = real_match.getInliers().ravel().tolist()\n",
    "\n",
    "    good_matches = []\n",
    "    for idx, mm in enumerate(matches_mask):\n",
    "        if mm == 1:\n",
    "            good_matches.append(matches_list[idx])\n",
    "    \n",
    "    # calculate horizontal distance between matched keypoints\n",
    "    kps1 = feature1.getKeypoints()\n",
    "    kps2 = feature2.getKeypoints()\n",
    "    width1 = img1.shape[1]\n",
    "\n",
    "    non_overlapping_widths = []\n",
    "    for m in good_matches:\n",
    "        overlap = kps2[m.trainIdx].pt[0] + width1 - kps1[m.queryIdx].pt[0]\n",
    "        \n",
    "        # too large overlap is outliers\n",
    "        if overlap < width1 * max_overlap_ratio:\n",
    "            non_overlapping_widths.append(width1 - overlap)\n",
    "\n",
    "    now = 0\n",
    "    if len(non_overlapping_widths) > 0:\n",
    "        now = np.mean(non_overlapping_widths)\n",
    "            \n",
    "    # show the matching status        \n",
    "    draw_params = dict(matchesMask=matches_mask,\n",
    "                       singlePointColor=None,\n",
    "                       matchColor=(0, 255, 0),\n",
    "                       flags=2)\n",
    "    res = cv.drawMatches(img1, \n",
    "                         feature1.getKeypoints(),\n",
    "                         img2, \n",
    "                         feature2.getKeypoints(),\n",
    "                         matches_list, None, **draw_params)\n",
    "    cv.putText(res, \n",
    "               'Good matches = ' + str(len(non_overlapping_widths)), \n",
    "               (50, 100), \n",
    "               cv.FONT_HERSHEY_SIMPLEX, \n",
    "               1, \n",
    "               (0, 0, 255), \n",
    "               2, \n",
    "               cv.LINE_AA)\n",
    "    cv.putText(res, \n",
    "               'NOW = ' + str(now), \n",
    "               (50, 150), \n",
    "               cv.FONT_HERSHEY_SIMPLEX, \n",
    "               1, \n",
    "               (0, 0, 255), \n",
    "               2, \n",
    "               cv.LINE_AA)\n",
    "    cv.namedWindow('match', cv.WINDOW_NORMAL)\n",
    "    cv.resizeWindow('match', 1200, 800)\n",
    "    cv.imshow('match', res)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()\n",
    "    \n",
    "    return now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now, calculate all adjacent now and ppds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0~1: now=772.5613020744877, ppd=31.892473570904436\n",
      "1~2: no matching points\n",
      "2~3: now=749.9456617567274, ppd=32.78954043074675\n",
      "3~4: now=715.8749413123497, ppd=29.625641194032227\n",
      "4~5: now=692.952143052045, ppd=31.229498168767844\n",
      "5~6: no matching points\n",
      "6~7: now=747.5978250676935, ppd=29.936637928568377\n",
      "7~8: now=503.24998187074567, ppd=20.422981301508695\n",
      "8~9: now=722.870005607605, ppd=32.60227603918273\n",
      "9~10: now=851.5272570158306, ppd=33.50880045669968\n",
      "10~11: now=749.8891052246094, ppd=32.92757328259107\n",
      "11~12: now=740.2287578830471, ppd=29.97872445876558\n",
      "12~13: now=677.7042263843974, ppd=29.38757124919135\n",
      "13~14: no matching points\n"
     ]
    }
   ],
   "source": [
    "ppds = []\n",
    "for idx in range(len(uris)-1):\n",
    "    in1 = os.path.join(folder, uris[idx])\n",
    "    in2 = os.path.join(folder, uris[idx+1])\n",
    "    \n",
    "    # yaw difference between two images\n",
    "    yaw_diff = yaws[idx+1] - yaws[idx]\n",
    "    if yaw_diff < 0:\n",
    "        yaw_diff += 360\n",
    "        \n",
    "    # calculate non-overlapping width\n",
    "    now = get_non_overlapping_width(in1, in2)\n",
    "    \n",
    "    # ppd = now / dyaw\n",
    "    if now != 0:\n",
    "        ppd = now / yaw_diff\n",
    "        ppds.append(ppd)\n",
    "        print('{}~{}: now={}, ppd={}'.format(idx, idx+1, now, ppd))\n",
    "    else:\n",
    "        print('{}~{}: no matching points'.format(idx, idx+1, now))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 or 3 cases when there can't be found any matches.\n",
    "\n",
    "As there are many candidates, it's OK for now. But it would be the risk when we stitch images. In this case, we should find out other ways to detect features.\n",
    "\n",
    "#### Average PPD(Pixels Per Degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.391065280087158"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppd = np.mean(ppds)\n",
    "ppd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The horizontal AOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.75146432233466"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1512/ppd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The horizontal angle-of-view **AOV_h** value was calculated from manual estimation. \n",
    "\n",
    "The feature matching algorithm depends on random selection of key points so that different results come out at every calculation. The AOV_h changes in the range of 49~50.6 degree while its value was 50.9 from the JSON file.\n",
    "\n",
    "The maximum deviation is 4% and this showed that we should believe the camera metrics values in despite of our scepticism.\n",
    "\n",
    "We can try the exp-SphericalAlignment experiment with this 49 degree value.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
